{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Famasmili/WAS/blob/main/IFT6135_A2_LSTM_LSTMv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_tbZlSEMRtQo"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "All the imports\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import logging\n",
        "import time\n",
        "import random\n",
        "import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G5w7H7dRgoS"
      },
      "source": [
        "# Dataset Generator (Do not modify)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FDZHmmZ0Rn8x"
      },
      "outputs": [],
      "source": [
        "def torch_copying_data(\n",
        "    L,\n",
        "    M,\n",
        "    A,\n",
        "    batch_shape=(),\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a dataset for a selective copying task.\n",
        "\n",
        "    Parameters:\n",
        "    L (int): Number of noise tokens\n",
        "    M (int): Number of tokens to memorize\n",
        "    A (int): Vocab size\n",
        "    batch_shape (tuple): Shape of the batch\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    tuple: Generated input sequence and target sequence\n",
        "    \"\"\"\n",
        "    tokens = torch.randint(low=1, high=A - 1, size=batch_shape + (M,))\n",
        "    total_batch = int(np.prod(batch_shape))\n",
        "    inds = torch.stack([torch.randperm(L + M)[:M] for _ in range(total_batch)], 0)\n",
        "    inds = inds.reshape(batch_shape + (M,))\n",
        "    inds, _ = inds.sort()\n",
        "    zeros_x = torch.zeros(batch_shape + (M + L,), dtype=torch.long)\n",
        "    zeros_x.scatter_(-1, inds, tokens)\n",
        "    markers = (A - 1) * torch.ones(batch_shape + (M,), dtype=torch.long)\n",
        "\n",
        "    x_ = torch.cat([zeros_x, markers], dim=-1)\n",
        "    y_ = torch.cat([tokens], dim=-1)\n",
        "    return x_, y_\n",
        "\n",
        "\n",
        "def generate_dataset(args):\n",
        "    \"\"\"\n",
        "    Generate a dataset based on the provided configuration.\n",
        "\n",
        "    Parameters:\n",
        "    args: Arguments for data generation\n",
        "\n",
        "    Returns:\n",
        "    tuple: Generated inputs and targets\n",
        "    \"\"\"\n",
        "    x, y = torch_copying_data(\n",
        "        args.l_noise, args.l_memorize, args.l_vocab, batch_shape=(args.batch_size,)\n",
        "    )\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkIzZmSLR1Tz"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRLB49EFR4Hr"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        Initialize the weight matrix here.\n",
        "\n",
        "        \"\"\"\n",
        "        self.weight_matrix = nn.Linear(input_size + hidden_size, 4 * hidden_size) # Write code here\n",
        "        self.init_params()\n",
        "\n",
        "        # We will use layer norm in the forward function for stable training\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def init_params(self):\n",
        "        nn.init.xavier_uniform_(self.weight_matrix.weight)\n",
        "        self.weight_matrix.bias = nn.Parameter(\n",
        "            torch.zeros_like(self.weight_matrix.bias)\n",
        "        )\n",
        "\n",
        "    def compute_gates_and_candidate_cell_state(self, x, h):\n",
        "        \"\"\"\n",
        "        x: (batch_size, input_size)\n",
        "\n",
        "        Returns the i, f, the candidate hidden state tilde(c) and o\n",
        "\n",
        "        (Refer to the assignment document for the notations)\n",
        "\n",
        "        Each of the four is expected to be of shape (batch_size, hidden_size)\n",
        "        Make sure to apply suitable activation functions as described in the assignment\n",
        "        \"\"\"\n",
        "        # Write code here\n",
        "        # Concatenate input and hidden state\n",
        "        combined = torch.cat((x, h), dim=1)\n",
        "        # Compute gates and candidate cell state\n",
        "        gates = self.weight_matrix(combined)\n",
        "        gate_chunks = torch.chunk(gates, 4, dim=1)\n",
        "         input_gate = torch.sigmoid(gate_chunks[0])\n",
        "        forget_gate = torch.sigmoid(gate_chunks[1])\n",
        "        candidate_cell_state = torch.tanh(gate_chunks[2])\n",
        "        output_gate = torch.sigmoid(gate_chunks[3])\n",
        "\n",
        "        #i, f, o, g = torch.split(gates, gates.size(1) // 4, dim=1)\n",
        "        #i = torch.sigmoid(i)\n",
        "        #f = torch.sigmoid(f)\n",
        "        #o = torch.sigmoid(o)\n",
        "        #g = torch.tanh(g)\n",
        "        return input_gate, forget_gate, candidate_cell_state, output_gate\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\"\n",
        "        x: (batch_size, input_size)\n",
        "\n",
        "        Returns the next computed hidden and cell state (h_next, c_next)\n",
        "\n",
        "        (Refer to the assignment document for the notations)\n",
        "\n",
        "        Each of the two is expected to be of shape (batch_size, hidden_size)\n",
        "\n",
        "        IMPORTANT: Apply the layer norm (initialized in __init__) to the c_next in the calculation\n",
        "        of h_next before applying the tanh activation\n",
        "        \"\"\"\n",
        "        # Write code here\n",
        "        h_next = torch.zeros_like(h)\n",
        "        c_next = torch.zeros_like(c)\n",
        "        input_gate, forget_gate, candidate_cell_state, output_gate = self.compute_gates_and_candidate_cell_state(x, h)\n",
        "        c_next = forget_gate * c + input_gate * candidate_cell_state\n",
        "        normalized_c_next = self.layer_norm(c_next)\n",
        "        h_next = output_gate * torch.tanh(normalized_c_next)\n",
        "        return h_next, c_next\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK5IBKr3SBNS"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size, n_layers, vocab_size, mem_len):\n",
        "        \"\"\"\n",
        "        DO NOT MODIFY\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size  # l_vocab\n",
        "        self.mem_len = mem_len  # l_memorize\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.cells = nn.ModuleList(\n",
        "            [LSTMCell(embed_dim, hidden_size)]\n",
        "            + [LSTMCell(hidden_size, hidden_size) for _ in range(n_layers - 1)]\n",
        "        )\n",
        "        self.clf = nn.Linear(embed_dim, vocab_size, bias=False)\n",
        "        self.out_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, embed_dim), nn.ReLU(), self.clf\n",
        "        )\n",
        "        self.clf.weight = self.embedding.weight\n",
        "\n",
        "    def get_model_hidden_states(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "        Returns the output hidden states, with output taken from the last l_memorize steps.\n",
        "        Make sure the code is general and works with multiple stacked layers of LSTM. The initial\n",
        "        hidden and cell states should be initialized to all zeros.\n",
        "\n",
        "        (Refer to the assignment document for the notations and explanation)\n",
        "\n",
        "        Output is expected to be of shape (batch_size, l_memorize, hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        seq_length = x.size(1)\n",
        "\n",
        "        final_hidden_states = []\n",
        "        hidden_states = [torch.zeros(batch_size, self.hidden_size).to(x.device) for _ in range(self.n_layers)]\n",
        "        cell_states = [torch.zeros(batch_size, self.hidden_size).to(x.device) for _ in range(self.n_layers)]\n",
        "        for i in range(seq_length):\n",
        "            input = x[:, i, :]\n",
        "\n",
        "            for j in range(self.n_layers):\n",
        "                hidden_states[j], cell_states[j] = self.cells[j](input, hidden_states[j], cell_states[j])\n",
        "                input = hidden_states[j]\n",
        "            if i >= x.size(1) - self.mem_len: # Only take the last l_memorize steps\n",
        "                final_hidden_states.append(hidden_states[-1])\n",
        "\n",
        "        return torch.stack(final_hidden_states, dim=1)\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, sequence_length)\n",
        "\n",
        "        Returns unnormalized logits as output, with output corresponding to last l_memorize steps.\n",
        "\n",
        "        You should only use the provided methods.\n",
        "\n",
        "        (Refer to the assignment document for the notations and explanation)\n",
        "\n",
        "        Output is expected to be of shape (batch_size, l_memorize, l_vocab)\n",
        "        \"\"\"\n",
        "        # Write code here\n",
        "        x = self.embedding(x) # (batch_size, sequence_length, embedding_dim) Embedding\n",
        "        hidden_states = self.get_model_hidden_states(x)\n",
        "        logits = self.out_mlp(hidden_states)\n",
        "        return logits\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36f5DtuaSD2c"
      },
      "source": [
        "# LSTMv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y39ZAHNBSFXF"
      },
      "outputs": [],
      "source": [
        "class LSTMv2Cell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        Initialize the weight matrix here\n",
        "        \"\"\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.weight_matrix = nn.Linear(input_size, 3 * hidden_size)  # Write code here\n",
        "\n",
        "        self.init_params()\n",
        "\n",
        "    def init_params(self):\n",
        "        nn.init.xavier_uniform_(self.weight_matrix.weight)\n",
        "        self.weight_matrix.bias = nn.Parameter(\n",
        "            torch.zeros_like(self.weight_matrix.bias)\n",
        "        )\n",
        "\n",
        "    def compute_gates_and_candidate_hidden_state(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, sequence_length, input_size)\n",
        "\n",
        "        Returns the i, f and the candidate hidden state tilde(h)\n",
        "\n",
        "        (Refer to the assignment document for the notations)\n",
        "\n",
        "        Each of the three is expected to be of shape (batch_size, sequence_length, hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        gates = self.weight_matrix(x)\n",
        "        gate_chunks = torch.chunk(gates, 3, dim=-1)\n",
        "        #print(f\"gates.size: {gates.size()}\")\n",
        "        forget_gate = torch.sigmoid(gate_chunks[0])\n",
        "        input_gate = torch.sigmoid(gate_chunks[1])\n",
        "        candidate_hidden_state = gate_chunks[2]\n",
        "\n",
        "\n",
        "\n",
        "        return forget_gate, input_gate, candidate_hidden_state\n",
        "\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, sequence_length, input_size)\n",
        "\n",
        "        Returns the i', f' and tilde(h)\n",
        "\n",
        "        (Refer to the assignment document for the notations)\n",
        "\n",
        "        Each of the three is expected to be of shape (batch_size, sequence_length, hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        forget_gate, input_gate, candidate_hidden_state = self.compute_gates_and_candidate_hidden_state(x)\n",
        "        denominator = forget_gate + input_gate\n",
        "        norm_forget_gate = forget_gate / denominator\n",
        "        norm_input_gate = input_gate / denominator\n",
        "\n",
        "        return norm_forget_gate, norm_input_gate, candidate_hidden_state\n",
        "        pass\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF3zTJ28SQUD"
      },
      "outputs": [],
      "source": [
        "class LSTMv2(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_size, n_layers, vocab_size, mem_len):\n",
        "        \"\"\"\n",
        "        DO NOT MODIFY\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size  # l_vocab\n",
        "        self.mem_len = mem_len  # l_memorize\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.cells = nn.ModuleList(\n",
        "            [LSTMv2Cell(embed_dim, hidden_size)]\n",
        "            + [LSTMv2Cell(hidden_size, hidden_size) for _ in range(n_layers - 1)]\n",
        "        )\n",
        "        self.clf = nn.Linear(embed_dim, vocab_size, bias=False)\n",
        "        self.out_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, embed_dim), nn.ReLU(), self.clf\n",
        "        )\n",
        "        self.clf.weight = self.embedding.weight\n",
        "\n",
        "    def parallel_scan_single_layer(self, f_norm, i_norm, h_tilde):\n",
        "        \"\"\"\n",
        "        DO NOT MODIFY\n",
        "\n",
        "        f_norm: Normalized forget gate. Shape: (batch_size, sequence_length, hidden_size)\n",
        "        i_norm: Normalized input gate. Shape: (batch_size, sequence_length, hidden_size)\n",
        "        h_tilde: Candidate hidden state. Shape: (batch_size, sequence_length, hidden_size)\n",
        "\n",
        "        Returns the computed hidden states at every step.\n",
        "        Output of the function is of shape (batch_size, sequence_length, hidden_size)\n",
        "        \"\"\"\n",
        "        batch_size = h_tilde.shape[0]\n",
        "        log_a_coeff = torch.log(f_norm + 1e-39)\n",
        "\n",
        "        h_0 = 0.5 * f_norm.new_ones(batch_size, 1, self.hidden_size)\n",
        "        h_norm = torch.where(h_tilde >= 0, h_tilde + 0.5, torch.sigmoid(h_tilde))\n",
        "        b_coeff = torch.cat([h_0, i_norm * h_norm], dim=1)\n",
        "        log_b_coeff = torch.log(b_coeff + 1e-39)\n",
        "\n",
        "        a_star = F.pad(torch.cumsum(log_a_coeff, dim=1), (0, 0, 1, 0))\n",
        "        log_h0_plus_b_star = torch.logcumsumexp(log_b_coeff - a_star, dim=1)\n",
        "        log_h = a_star + log_h0_plus_b_star\n",
        "\n",
        "        return torch.exp(log_h)[:, 1:]\n",
        "\n",
        "    def get_model_hidden_states(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "        Returns the output hidden states, with output taken from the last l_memorize steps.\n",
        "        Make sure the code is general and works with multiple stacked layers of LSTMv2.\n",
        "        You should use the provided parallel scan method to get hidden states.\n",
        "\n",
        "        (Refer to the assignment document for the notations and explanation)\n",
        "\n",
        "        Output is expected to be of shape (batch_size, l_memorize, hidden_size)\n",
        "        \"\"\"\n",
        "        # Write code here\n",
        "        hidden_states = []\n",
        "        #print(f\"x.size in get_model_hidden_states: {x.size()}\")\n",
        "\n",
        "        input_layer = x\n",
        "\n",
        "        for j in range(self.n_layers):\n",
        "            f_norm, i_norm, h_tilde = self.cells[j](input_layer)\n",
        "            output_layer = self.parallel_scan_single_layer(f_norm, i_norm, h_tilde)\n",
        "            #print(f\"hidden_state[{j}].size after parallel_scan_single_layer: {hidden_state[j].size()}\")\n",
        "            input_layer = output_layer\n",
        "\n",
        "        hidden_states = output_layer[:, -self.mem_len:, :]\n",
        "\n",
        "        return hidden_states\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch_size, sequence_length)\n",
        "\n",
        "        Returns unnormalized logits as output, with output corresponding to last l_memorize steps.\n",
        "\n",
        "        You should only use the provided methods.\n",
        "\n",
        "        (Refer to the assignment document for the notations and explanation)\n",
        "\n",
        "        Output is expected to be of shape (batch_size, l_memorize, l_vocab)\n",
        "        \"\"\"\n",
        "        # Write code here\n",
        "        #print(f\"x.size in lstmv2 module forward before embedding: {x.size()}\")\n",
        "        x = self.embedding(x)\n",
        "        #print(f\"x.size in lstmv2 module forward after embedding: {x.size()}\")\n",
        "        hidden_states = self.get_model_hidden_states(x)\n",
        "        logits = self.out_mlp(hidden_states)\n",
        "        return logits\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk3kQfygSTby"
      },
      "source": [
        "# Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSEafZpqSXWh"
      },
      "outputs": [],
      "source": [
        "def seed_experiment(seed):\n",
        "    \"\"\"Seed the pseudorandom number generator, for repeatability.\n",
        "\n",
        "    Args:\n",
        "        seed (int): random seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "def init_model_and_optimizer(args, device):\n",
        "    if args.model == lstm_model:\n",
        "        model = LSTM(\n",
        "            args.embed_dim,\n",
        "            4 * args.embed_dim,\n",
        "            args.n_layers,\n",
        "            args.l_vocab,\n",
        "            args.l_memorize,\n",
        "        )\n",
        "        model = model.to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    elif args.model == lstmv2_model:\n",
        "        model = LSTMv2(\n",
        "            args.embed_dim,\n",
        "            4 * args.embed_dim,\n",
        "            args.n_layers,\n",
        "            args.l_vocab,\n",
        "            args.l_memorize,\n",
        "        )\n",
        "        model = model.to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    else:\n",
        "        raise ModuleNotFoundError\n",
        "\n",
        "    return model, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUUN1sITSsTS"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train(args, model, optimizer):\n",
        "    \"\"\"\n",
        "    Train the model.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    wandb.init(project=\"lstm_models\", name=\"training_records\")\n",
        "    wandb.config.update(args)\n",
        "    start_time = time.time()\n",
        "    for step in range(args.n_steps):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        \"\"\"\n",
        "        Generate a batch of data.\n",
        "        Inputs: (batch_size, l_noise + 2*l_memorize)\n",
        "        Targets: (batch_size, l_memorize)\n",
        "        \"\"\"\n",
        "        inputs, targets = generate_dataset(args)\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)  # Expected shape is (batch size, l_memorize, l_vocab)\n",
        "        loss = (\n",
        "            criterion(outputs.view(-1, args.l_vocab), targets.view(-1)) * args.l_vocab\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping for stable training\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Logging useful quantities\n",
        "        step_loss = loss.item()\n",
        "        total = targets.size(0) * targets.size(1)\n",
        "        correct = (outputs.argmax(-1) == targets).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        torch.cuda.synchronize() # Ensure all computations are finished\n",
        "        peak_memory = torch.cuda.max_memory_allocated(device) / (1024 ** 2) # In MB\n",
        "        wandb.log({\"peak_gpu_memory\": peak_memory})\n",
        "        #wandb.log({\"loss\": step_loss/args.batch_size})\n",
        "        #wandb.log({\"accuracy\": accuracy})\n",
        "\n",
        "        one_step_time_log = time.time()\n",
        "        one_step_time_log -= start_time\n",
        "        if step == 0:\n",
        "            print(f\"Training one step of {args.model} took {one_step_time_log:.2f} seconds\")\n",
        "        #print(f\"Training one step of {args.model} took {one_step_time_log/60:.2f} minutes\")\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(\n",
        "                f\"Step [{step+1}/{args.n_steps}], Loss: {step_loss/args.batch_size:.4f}, Accuracy: {accuracy:.2f}%\"\n",
        "            )\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Training completed in: {(end_time - start_time)/60:.2f} minutes\")\n",
        "    print(f\"Final training accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Final training loss: {step_loss/args.batch_size:.4f}\")\n",
        "    print(f\"Total number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
        "    #print(f\"Total number of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "    #print(f\"Total number of non-trainable parameters: {sum(p.numel() for p in model.parameters() if not p.requires_grad)}\")\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def test(args, model):\n",
        "    \"\"\"\n",
        "    Test the learned model on the test set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for step in range(args.eval_steps):\n",
        "            inputs, targets = generate_dataset(args)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            correct += (outputs.argmax(-1) == targets).sum().item()\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\n",
        "        f\"Test Accuracy: {100* correct/(args.eval_steps * args.batch_size * args.l_memorize):.2f}%\"\n",
        "    )\n",
        "    print(f\"Testing completed in: {(end_time - start_time)/60:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBn1o51YS_Zf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943,
          "referenced_widgets": [
            "0e053870a90948f78a8170dc6468e9e6",
            "579622dcfcc04123befa98440a02bd24",
            "7bb98c76da224cc990da2994f7d47571",
            "ba7d6c3c523743dabe1720dfc2a24da9",
            "0371651c3b47450b9a258d49a4c393aa",
            "ebdc9c3f01b24247a437cc1d505b69a0",
            "b8330bce658d4671938f45a37c79922b",
            "1f8137071c104ec69708bdeea1aec90e"
          ]
        },
        "outputId": "1d851618-133b-414a-d6e6-4c92c3eeecc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:s69uqixd) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.013 MB of 0.013 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e053870a90948f78a8170dc6468e9e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>peak_gpu_memory</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>peak_gpu_memory</td><td>166.31348</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">training_records</strong> at: <a href='https://wandb.ai/rabbibinda_/lstm_models/runs/s69uqixd' target=\"_blank\">https://wandb.ai/rabbibinda_/lstm_models/runs/s69uqixd</a><br/> View project at: <a href='https://wandb.ai/rabbibinda_/lstm_models' target=\"_blank\">https://wandb.ai/rabbibinda_/lstm_models</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241102_233916-s69uqixd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:s69uqixd). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241103_000057-e8193vh4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rabbibinda_/lstm_models/runs/e8193vh4' target=\"_blank\">training_records</a></strong> to <a href='https://wandb.ai/rabbibinda_/lstm_models' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rabbibinda_/lstm_models' target=\"_blank\">https://wandb.ai/rabbibinda_/lstm_models</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rabbibinda_/lstm_models/runs/e8193vh4' target=\"_blank\">https://wandb.ai/rabbibinda_/lstm_models/runs/e8193vh4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training one step of LSTM took 0.50 seconds\n",
            "Step [1/2000], Loss: 0.8229, Accuracy: 7.91%\n",
            "Step [101/2000], Loss: 0.6539, Accuracy: 8.11%\n",
            "Step [201/2000], Loss: 0.6414, Accuracy: 12.40%\n",
            "Step [301/2000], Loss: 0.6266, Accuracy: 14.84%\n",
            "Step [401/2000], Loss: 0.6216, Accuracy: 15.43%\n",
            "Step [501/2000], Loss: 0.6207, Accuracy: 17.09%\n",
            "Step [601/2000], Loss: 0.6119, Accuracy: 16.21%\n",
            "Step [701/2000], Loss: 0.6012, Accuracy: 18.26%\n",
            "Step [801/2000], Loss: 0.5931, Accuracy: 18.16%\n",
            "Step [901/2000], Loss: 0.5907, Accuracy: 19.24%\n",
            "Step [1001/2000], Loss: 0.5814, Accuracy: 21.78%\n",
            "Step [1101/2000], Loss: 0.5742, Accuracy: 18.85%\n",
            "Step [1201/2000], Loss: 0.5693, Accuracy: 21.68%\n",
            "Step [1301/2000], Loss: 0.5586, Accuracy: 21.68%\n",
            "Step [1401/2000], Loss: 0.5549, Accuracy: 22.27%\n",
            "Step [1501/2000], Loss: 0.5406, Accuracy: 24.41%\n",
            "Step [1601/2000], Loss: 0.5378, Accuracy: 25.78%\n",
            "Step [1701/2000], Loss: 0.5445, Accuracy: 24.90%\n",
            "Step [1801/2000], Loss: 0.5347, Accuracy: 26.76%\n",
            "Step [1901/2000], Loss: 0.5166, Accuracy: 28.81%\n",
            "Training completed in: 18.36 minutes\n",
            "Final training accuracy: 25.88%\n",
            "Final training loss: 0.5492\n",
            "Total number of parameters: 346688\n",
            "Test Accuracy: 26.26%\n",
            "Testing completed in: 0.03 minutes\n"
          ]
        }
      ],
      "source": [
        "seed_experiment(1) #Do not change the seed\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "lstm_model = \"LSTM\"\n",
        "lstmv2_model = \"LSTMv2\"\n",
        "\n",
        "class Args:\n",
        "    embed_dim = 64\n",
        "    l_noise=512\n",
        "    l_memorize=16\n",
        "    l_vocab = 16\n",
        "    batch_size= 64\n",
        "    n_steps=2000\n",
        "    eval_steps=10\n",
        "    n_layers=1\n",
        "    model=lstm_model\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# Define model\n",
        "model, optimizer = init_model_and_optimizer(args, device)\n",
        "\n",
        "model = train(args, model, optimizer)\n",
        "test(args, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training using l_noise = 256\n",
        "\n",
        " Training one step of LSTM took 1.95 seconds\n",
        "\n",
        " 2 Step [1/2000], Loss: 0.8230, Accuracy: 7.81%\n",
        "\n",
        " 3 Step [101/2000], Loss: 0.6501, Accuracy: 10.06%\n",
        "\n",
        " 4 Step [201/2000], Loss: 0.6331, Accuracy: 12.79%\n",
        "\n",
        " 5 Step [301/2000], Loss: 0.6124, Accuracy: 16.31%\n",
        "\n",
        " 6 Step [401/2000], Loss: 0.6028, Accuracy: 15.14%\n",
        "\n",
        " 7 Step [501/2000], Loss: 0.5894, Accuracy: 18.16%\n",
        "\n",
        " 8 Step [601/2000], Loss: 0.5764, Accuracy: 18.65%\n",
        "\n",
        " 9 Step [701/2000], Loss: 0.5635, Accuracy: 20.41%\n",
        "\n",
        "10 Step [801/2000], Loss: 0.5648, Accuracy: 20.\n",
        "41%\n",
        "\n",
        "11 Step [901/2000], Loss: 0.5418, Accuracy: 21.48%\n",
        "\n",
        "12 Step [1001/2000], Loss: 0.5288, Accuracy: 24.80%\n",
        "\n",
        "13 Step [1101/2000], Loss: 0.5066, Accuracy: 26.17%\n",
        "\n",
        "14 Step [1201/2000], Loss: 0.4997, Accuracy: 29.20%\n",
        "\n",
        "15 Step [1301/2000], Loss: 0.4953, Accuracy: 27.64%\n",
        "\n",
        "16 Step [1401/2000], Loss: 0.4912, Accuracy: 29.30%\n",
        "\n",
        "17 Step [1501/2000], Loss: 0.4759, Accuracy: 31.25%\n",
        "\n",
        "18 Step [1601/2000], Loss: 0.4766, Accuracy: 30.57%\n",
        "\n",
        "19 Step [1701/2000], Loss: 0.4730, Accuracy: 33.20%\n",
        "\n",
        "20 Step [1801/2000], Loss: 0.4462, Accuracy: 33.59%\n",
        "\n",
        "21 Step [1901/2000], Loss: 0.4381, Accuracy: 34.77%\n",
        "\n",
        "22 Training completed in: 9.51 minutes\n",
        "\n",
        "23 Final training accuracy: 36.91%\n",
        "\n",
        "24 Final training loss: 0.4278\n",
        "\n",
        "25 Total number of parameters: 346688\n",
        "\n",
        "26 Test Accuracy: 35.95%\n",
        "\n",
        "27 Testing completed in: 0.02 minutes"
      ],
      "metadata": {
        "id": "SxH_2kVf6W0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training vanilla LSTM with l_noise = 512\n",
        "\n",
        "1 Training one step of LSTM took 0.50 seconds\n",
        "\n",
        " 2 Step [1/2000], Loss: 0.8229, Accuracy: 7.91%\n",
        "\n",
        " 3 Step [101/2000], Loss: 0.6539, Accuracy: 8.11%\n",
        "\n",
        " 4 Step [201/2000], Loss: 0.6414, Accuracy: 12.40%\n",
        "\n",
        " 5 Step [301/2000], Loss: 0.6266, Accuracy: 14.84%\n",
        "\n",
        " 6 Step [401/2000], Loss: 0.6216, Accuracy: 15.43%\n",
        "\n",
        " 7 Step [501/2000], Loss: 0.6207, Accuracy: 17.09%\n",
        "\n",
        " 8 Step [601/2000], Loss: 0.6119, Accuracy: 16.21%\n",
        "\n",
        " 9 Step [701/2000], Loss: 0.6012, Accuracy: 18.26%\n",
        "\n",
        "10 Step [801/2000], Loss: 0.5931, Accuracy: 18.16%\n",
        "\n",
        "11 Step [901/2000], Loss: 0.5907, Accuracy: 19.24%\n",
        "\n",
        "12 Step [1001/2000], Loss: 0.5814, Accuracy: 21.78%\n",
        "\n",
        "13 Step [1101/2000], Loss: 0.5742, Accuracy: 18.85%\n",
        "\n",
        "14 Step [1201/2000], Loss: 0.5693, Accuracy: 21.68%\n",
        "\n",
        "15 Step [1301/2000], Loss: 0.5586, Accuracy: 21.68%\n",
        "\n",
        "16 Step [1401/2000], Loss: 0.5549, Accuracy: 22.27%\n",
        "\n",
        "17 Step [1501/2000], Loss: 0.5406, Accuracy: 24.41%\n",
        "\n",
        "18 Step [1601/2000], Loss: 0.5378, Accuracy: 25.78%\n",
        "\n",
        "19 Step [1701/2000], Loss: 0.5445, Accuracy: 24.90%\n",
        "\n",
        "20 Step [1801/2000], Loss: 0.5347, Accuracy: 26.76%\n",
        "\n",
        "21 Step [1901/2000], Loss: 0.5166, Accuracy: 28.81%\n",
        "\n",
        "22 Training completed in: 18.36 minutes\n",
        "\n",
        "23 Final training accuracy: 25.88%\n",
        "\n",
        "24 Final training loss: 0.5492\n",
        "\n",
        "25 Total number of parameters: 346688\n",
        "\n",
        "26 Test Accuracy: 26.26%\n",
        "\n",
        "27 Testing completed in: 0.03 minutes"
      ],
      "metadata": {
        "id": "cUi9kL49aOay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_experiment(1) #Do not change the seed\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "lstm_model = \"LSTM\"\n",
        "lstmv2_model = \"LSTMv2\"\n",
        "\n",
        "class Args:\n",
        "    embed_dim = 64\n",
        "    l_noise=256\n",
        "    l_memorize=16\n",
        "    l_vocab = 16\n",
        "    batch_size= 64\n",
        "    n_steps=2000\n",
        "    eval_steps=10\n",
        "    n_layers=2\n",
        "    model=lstmv2_model\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# Define model\n",
        "model, optimizer = init_model_and_optimizer(args, device)\n",
        "\n",
        "model = train(args, model, optimizer)\n",
        "test(args, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943,
          "referenced_widgets": [
            "101405877069493ca828db291e6bcefc",
            "8acb9209abb347ff8daa2022507078fe",
            "adb403ae03744f62bf1df63596e4bbb2",
            "4ac7df1d503f475b9d001e9123607db5",
            "7793e6e0dc464ae0b3eefade0b33a431",
            "1b3ecc2441844f7191e0eb71da2d1240",
            "603fca719f9a49c5980cd57458dd11c5",
            "b8d9c28715364cce80a93dd7b519ee33"
          ]
        },
        "id": "aEiZEwXrsUUb",
        "outputId": "30f288fb-bd15-423f-a0ff-35e86b945227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:6ns9gfgt) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.013 MB of 0.013 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "101405877069493ca828db291e6bcefc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>peak_gpu_memory</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>peak_gpu_memory</td><td>832.81348</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">training_records</strong> at: <a href='https://wandb.ai/rabbibinda_/lstm_models/runs/6ns9gfgt' target=\"_blank\">https://wandb.ai/rabbibinda_/lstm_models/runs/6ns9gfgt</a><br/> View project at: <a href='https://wandb.ai/rabbibinda_/lstm_models' target=\"_blank\">https://wandb.ai/rabbibinda_/lstm_models</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241103_004119-6ns9gfgt/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:6ns9gfgt). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241103_010052-8uxcbit2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rabbibinda_/lstm_models/runs/8uxcbit2' target=\"_blank\">training_records</a></strong> to <a href='https://wandb.ai/rabbibinda_/lstm_models' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rabbibinda_/lstm_models' target=\"_blank\">https://wandb.ai/rabbibinda_/lstm_models</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rabbibinda_/lstm_models/runs/8uxcbit2' target=\"_blank\">https://wandb.ai/rabbibinda_/lstm_models/runs/8uxcbit2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training one step of LSTMv2 took 0.05 seconds\n",
            "Step [1/2000], Loss: 1.1392, Accuracy: 6.05%\n",
            "Step [101/2000], Loss: 0.6613, Accuracy: 7.42%\n",
            "Step [201/2000], Loss: 0.6610, Accuracy: 6.64%\n",
            "Step [301/2000], Loss: 0.6612, Accuracy: 7.81%\n",
            "Step [401/2000], Loss: 0.6576, Accuracy: 8.01%\n",
            "Step [501/2000], Loss: 0.6405, Accuracy: 12.70%\n",
            "Step [601/2000], Loss: 0.5972, Accuracy: 17.29%\n",
            "Step [701/2000], Loss: 0.5557, Accuracy: 20.21%\n",
            "Step [801/2000], Loss: 0.5334, Accuracy: 23.34%\n",
            "Step [901/2000], Loss: 0.5101, Accuracy: 24.32%\n",
            "Step [1001/2000], Loss: 0.4871, Accuracy: 24.90%\n",
            "Step [1101/2000], Loss: 0.4615, Accuracy: 29.10%\n",
            "Step [1201/2000], Loss: 0.4521, Accuracy: 31.74%\n",
            "Step [1301/2000], Loss: 0.4348, Accuracy: 33.11%\n",
            "Step [1401/2000], Loss: 0.4169, Accuracy: 34.67%\n",
            "Step [1501/2000], Loss: 0.4007, Accuracy: 37.40%\n",
            "Step [1601/2000], Loss: 0.3879, Accuracy: 39.16%\n",
            "Step [1701/2000], Loss: 0.3725, Accuracy: 41.21%\n",
            "Step [1801/2000], Loss: 0.3624, Accuracy: 42.68%\n",
            "Step [1901/2000], Loss: 0.3432, Accuracy: 48.63%\n",
            "Training completed in: 1.34 minutes\n",
            "Final training accuracy: 48.63%\n",
            "Final training loss: 0.3320\n",
            "Total number of parameters: 264768\n",
            "Test Accuracy: 47.56%\n",
            "Testing completed in: 0.00 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training LSTMv2 using l_noise = 256\n",
        "\n",
        "1 Training one step of LSTMv2 took 0.40 seconds\n",
        "\n",
        " 2 Step [1/2000], Loss: 2.0018, Accuracy: 7.03%\n",
        "\n",
        " 3 Step [101/2000], Loss: 0.6619, Accuracy: 7.03%\n",
        "\n",
        " 4 Step [201/2000], Loss: 0.6617, Accuracy: 7.03%\n",
        "\n",
        " 5 Step [301/2000], Loss: 0.6554, Accuracy: 8.89%\n",
        "\n",
        " 6 Step [401/2000], Loss: 0.6545, Accuracy: 9.38%\n",
        "\n",
        " 7 Step [501/2000], Loss: 0.6459, Accuracy: 13.38%\n",
        "\n",
        " 8 Step [601/2000], Loss: 0.6347, Accuracy: 13.57%\n",
        "\n",
        " 9 Step [701/2000], Loss: 0.6186, Accuracy: 15.23%\n",
        "\n",
        "10 Step [801/2000], Loss: 0.6027, Accuracy: 15.72%\n",
        "\n",
        "11 Step [901/2000], Loss: 0.5804, Accuracy: 18.75%\n",
        "\n",
        "12 Step [1001/2000], Loss: 0.5679, Accuracy: 20.90%\n",
        "\n",
        "13 Step [1101/2000], Loss: 0.5635, Accuracy: 20.61%\n",
        "\n",
        "14 Step [1201/2000], Loss: 0.5587, Accuracy: 21.78%\n",
        "\n",
        "15 Step [1301/2000], Loss: 0.5484, Accuracy: 20.70%\n",
        "\n",
        "16 Step [1401/2000], Loss: 0.5590, Accuracy: 19.34%\n",
        "\n",
        "17 Step [1501/2000], Loss: 0.5465, Accuracy: 21.00%\n",
        "\n",
        "18 Step [1601/2000], Loss: 0.5462, Accuracy: 21.39%\n",
        "\n",
        "19 Step [1701/2000], Loss: 0.5491, Accuracy: 21.88%\n",
        "\n",
        "20 Step [1801/2000], Loss: 0.5417, Accuracy: 23.14%\n",
        "\n",
        "21 Step [1901/2000], Loss: 0.5351, Accuracy: 21.09%\n",
        "\n",
        "22 Training completed in: 0.69 minutes\n",
        "\n",
        "23 Final training accuracy: 23.14%\n",
        "\n",
        "24 Final training loss: 0.5339\n",
        "\n",
        "25 Total number of parameters: 67392\n",
        "\n",
        "26 Test Accuracy: 22.60%\n",
        "\n",
        "27 Testing completed in: 0.00 minutes"
      ],
      "metadata": {
        "id": "6Ase2t0Ja2_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training using LSTMv2 with l_noise = 512\n",
        "\n",
        "1 Training one step of LSTMv2 took 0.05 seconds\n",
        "\n",
        " 2 Step [1/2000], Loss: 2.0014, Accuracy: 7.03%\n",
        "\n",
        " 3 Step [101/2000], Loss: 0.6602, Accuracy: 6.84%\n",
        "\n",
        " 4 Step [201/2000], Loss: 0.6637, Accuracy: 6.84%\n",
        "\n",
        " 5 Step [301/2000], Loss: 0.6605, Accuracy: 6.84%\n",
        "\n",
        " 6 Step [401/2000], Loss: 0.6624, Accuracy: 7.42%\n",
        "\n",
        " 7 Step [501/2000], Loss: 0.6616, Accuracy: 8.20%\n",
        "\n",
        " 8 Step [601/2000], Loss: 0.6503, Accuracy: 9.67%\n",
        "\n",
        " 9 Step [701/2000], Loss: 0.6490, Accuracy: 10.94%\n",
        "\n",
        "10 Step [801/2000], Loss: 0.6377, Accuracy: 13.18%\n",
        "\n",
        "11 Step [901/2000], Loss: 0.6330, Accuracy: 11.62%\n",
        "\n",
        "12 Step [1001/2000], Loss: 0.6205, Accuracy: 16.21%\n",
        "\n",
        "13 Step [1101/2000], Loss: 0.6152, Accuracy: 16.80%\n",
        "\n",
        "14 Step [1201/2000], Loss: 0.6088, Accuracy: 18.46%\n",
        "\n",
        "15 Step [1301/2000], Loss: 0.6030, Accuracy: 16.41%\n",
        "\n",
        "16 Step [1401/2000], Loss: 0.5946, Accuracy: 18.16%\n",
        "\n",
        "17 Step [1501/2000], Loss: 0.5878, Accuracy: 18.75%\n",
        "\n",
        "18 Step [1601/2000], Loss: 0.5755, Accuracy: 20.80%\n",
        "\n",
        "19 Step [1701/2000], Loss: 0.5756, Accuracy: 19.14%\n",
        "\n",
        "20 Step [1801/2000], Loss: 0.5753, Accuracy: 18.75%\n",
        "\n",
        "21 Step [1901/2000], Loss: 0.5726, Accuracy: 19.92%\n",
        "\n",
        "22 Training completed in: 1.20 minutes\n",
        "\n",
        "23 Final training accuracy: 21.58%\n",
        "\n",
        "24 Final training loss: 0.5649\n",
        "\n",
        "25 Total number of parameters: 67392\n",
        "\n",
        "26 Test Accuracy: 20.91%\n",
        "\n",
        "27 Testing completed in: 0.00 minutes"
      ],
      "metadata": {
        "id": "7EsOAGUGdEoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "\n",
        "def collect_training_data(model_type, num_layers, noise=256):\n",
        "    \"\"\"\n",
        "    Train model and collect loss and accuracy data. This function follows the\n",
        "    design and implementation provided in the code for training and testing the\n",
        "    models.\n",
        "    \"\"\"\n",
        "\n",
        "    # Reset seeds for reproducibility\n",
        "    seed_experiment(1)\n",
        "\n",
        "    class Args:\n",
        "        embed_dim = 64\n",
        "        l_noise = noise\n",
        "        l_memorize = 16\n",
        "        l_vocab = 16\n",
        "        batch_size = 64\n",
        "        n_steps = 2000\n",
        "        eval_steps = 10\n",
        "        model = model_type\n",
        "        n_layers = num_layers\n",
        "\n",
        "    args = Args()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Initialize model and optimizer\n",
        "    model, optimizer = init_model_and_optimizer(args, device)\n",
        "\n",
        "    # Lists to store metrics\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for step in range(args.n_steps):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Generate batch\n",
        "        inputs, targets = generate_dataset(args)\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.view(-1, args.l_vocab), targets.view(-1)) * args.l_vocab\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Record metrics\n",
        "        step_loss = loss.item()\n",
        "        total = targets.size(0) * targets.size(1)\n",
        "        correct = (outputs.argmax(-1) == targets).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        losses.append(step_loss/args.batch_size)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    # Test accuracy\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for step in range(args.eval_steps):\n",
        "            inputs, targets = generate_dataset(args)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            correct += (outputs.argmax(-1) == targets).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * correct/(args.eval_steps * args.batch_size * args.l_memorize)\n",
        "\n",
        "    return losses, accuracies, test_accuracy"
      ],
      "metadata": {
        "id": "slKpfaR1y720"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves():\n",
        "    \"\"\"\n",
        "    Create training curves for both models with 1 and 3 layers\n",
        "    \"\"\"\n",
        "\n",
        "    #plt.style.use('seaborn')\n",
        "    sns.set_theme(style=\"darkgrid\")\n",
        "    sns.set_palette(\"husl\")\n",
        "\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Configurations data\n",
        "    configs = [\n",
        "        (lstm_model, 1),\n",
        "        (lstmv2_model, 1),\n",
        "        (lstm_model, 3),\n",
        "        (lstmv2_model, 3)\n",
        "    ]\n",
        "\n",
        "    results = {} # To store the results\n",
        "    for model_type, n_layers in configs:\n",
        "        model_name = f\"{model_type}-{n_layers}layer\"\n",
        "        losses, accs, test_acc = collect_training_data(model_type, n_layers)\n",
        "        results[model_name] = {\n",
        "            'losses': losses,\n",
        "            'accuracies': accs,\n",
        "            'test_acc': test_acc\n",
        "        }\n",
        "\n",
        "    # Plot 1-layer results\n",
        "    steps = range(len(results[f'{lstm_model}-1layer']['losses']))\n",
        "    ax1.plot(steps, results[f'{lstm_model}-1layer']['losses'],\n",
        "             label=f'LSTM (Test: {results[f\"{lstm_model}-1layer\"][\"test_acc\"]:.1f}%)',\n",
        "             linewidth=2)\n",
        "    ax1.plot(steps, results[f'{lstmv2_model}-1layer']['losses'],\n",
        "             label=f'LSTMv2 (Test: {results[f\"{lstmv2_model}-1layer\"][\"test_acc\"]:.1f}%)',\n",
        "             linewidth=2)\n",
        "    ax1.set_title('Training Loss (1 Layer)', fontsize=12, pad=15)\n",
        "    ax1.set_xlabel('Training Steps', fontsize=10)\n",
        "    ax1.set_ylabel('Loss', fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(fontsize=9)\n",
        "\n",
        "    # Plot 3-layer results\n",
        "    ax2.plot(steps, results[f'{lstm_model}-3layer']['losses'],\n",
        "             label=f'LSTM (Test: {results[f\"{lstm_model}-3layer\"][\"test_acc\"]:.1f}%)',\n",
        "             linewidth=2)\n",
        "    ax2.plot(steps, results[f'{lstmv2_model}-3layer']['losses'],\n",
        "             label=f'LSTMv2 (Test: {results[f\"{lstmv2_model}-3layer\"][\"test_acc\"]:.1f}%)',\n",
        "             linewidth=2)\n",
        "    ax2.set_title('Training Loss (3 Layers)', fontsize=12, pad=15)\n",
        "    ax2.set_xlabel('Training Steps', fontsize=10)\n",
        "    ax2.set_ylabel('Loss', fontsize=10)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.legend(fontsize=9)\n",
        "\n",
        "    plt.suptitle('LSTM vs LSTMv2 Training Loss Comparison\\n(l_noise=256)',\n",
        "                fontsize=14, y=1.05)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig('lstm_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Return results for analysis\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "hj8jAUPu00yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the analysis\n",
        "results = plot_training_curves()\n",
        "\n",
        "# Print tabulated results\n",
        "from tabulate import tabulate\n",
        "\n",
        "headers = [\"Model\", \"Layers\", \"Test Accuracy (%)\", \"Final Training Loss\"]\n",
        "table_data = []\n",
        "for model in [\"LSTM\", \"LSTMv2\"]:\n",
        "    for layers in [1, 3]:\n",
        "        key = f\"{model}-{layers}layer\"\n",
        "        table_data.append([\n",
        "            model,\n",
        "            layers,\n",
        "            f\"{results[key]['test_acc']:.2f}\",\n",
        "            f\"{results[key]['losses'][-1]:.4f}\"\n",
        "        ])\n",
        "\n",
        "print(\"\\nPerformance Summary:\")\n",
        "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
      ],
      "metadata": {
        "id": "cjA05OCK0_H8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e053870a90948f78a8170dc6468e9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_579622dcfcc04123befa98440a02bd24",
              "IPY_MODEL_7bb98c76da224cc990da2994f7d47571"
            ],
            "layout": "IPY_MODEL_ba7d6c3c523743dabe1720dfc2a24da9"
          }
        },
        "579622dcfcc04123befa98440a02bd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0371651c3b47450b9a258d49a4c393aa",
            "placeholder": "​",
            "style": "IPY_MODEL_ebdc9c3f01b24247a437cc1d505b69a0",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "7bb98c76da224cc990da2994f7d47571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8330bce658d4671938f45a37c79922b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f8137071c104ec69708bdeea1aec90e",
            "value": 1
          }
        },
        "ba7d6c3c523743dabe1720dfc2a24da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0371651c3b47450b9a258d49a4c393aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebdc9c3f01b24247a437cc1d505b69a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8330bce658d4671938f45a37c79922b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8137071c104ec69708bdeea1aec90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "101405877069493ca828db291e6bcefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8acb9209abb347ff8daa2022507078fe",
              "IPY_MODEL_adb403ae03744f62bf1df63596e4bbb2"
            ],
            "layout": "IPY_MODEL_4ac7df1d503f475b9d001e9123607db5"
          }
        },
        "8acb9209abb347ff8daa2022507078fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7793e6e0dc464ae0b3eefade0b33a431",
            "placeholder": "​",
            "style": "IPY_MODEL_1b3ecc2441844f7191e0eb71da2d1240",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "adb403ae03744f62bf1df63596e4bbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_603fca719f9a49c5980cd57458dd11c5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8d9c28715364cce80a93dd7b519ee33",
            "value": 1
          }
        },
        "4ac7df1d503f475b9d001e9123607db5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7793e6e0dc464ae0b3eefade0b33a431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b3ecc2441844f7191e0eb71da2d1240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "603fca719f9a49c5980cd57458dd11c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8d9c28715364cce80a93dd7b519ee33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}